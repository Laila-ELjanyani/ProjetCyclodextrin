{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4b79626c-e722-4f4f-9af4-1a716c6d4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "721fced1-f252-4443-bc4f-eac6b69b7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('xtrainCyclodextrin.csv')\n",
    "dataset_test = pd.read_csv('xtestCyclodextrin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2f9e577b-f539-43c6-9329-72e68ac3be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Erreur_not_null = dataset_train[dataset_train['Erreur'].isnull()==False]\n",
    "# #Check for outliers using boxplot\n",
    "# import seaborn as sns\n",
    "# from scipy.stats import zscore\n",
    "# from scipy import stats\n",
    "# sns.boxplot(data=data_Erreur_not_null, x=\"Erreur\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d3161355-ae80-4495-8cf1-26bc14ce82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Erreur_not_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a74d1af-ff9c-4020-8de5-26e496784fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check for outliers using boxplot\n",
    "# import seaborn as sns\n",
    "# from scipy.stats import zscore\n",
    "# from scipy import stats\n",
    "# sns.boxplot(data=dataset_train, x=\"K\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3edf45cc-6b77-4054-9409-07f1a2bf0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = dataset_train[(dataset_train['Erreur']<=1) | (dataset_train['Erreur'].isnull()==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "47abf5d2-7305-4c6e-a9e0-a06aecc934f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset_train\n",
    "x_test = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0eac7844-367c-48e3-be19-b1ea6bcda975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2940, 49)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8798a36a-857a-4e35-9410-3677cc8822fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import IsolationForest\n",
    "# iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "# x_train['Outlier'] = iso_forest.fit_predict(x_train[['K']])\n",
    "# x_train = x_train[x_train['Outlier'] != -1].drop(columns=['Outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "01b86872-20bd-41d9-8571-e1e28433410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "(2940, 50)\n",
      "\n",
      "Outliers:\n",
      "           K\n",
      "9      37300\n",
      "27      9420\n",
      "38      6000\n",
      "54    107358\n",
      "58      9560\n",
      "...      ...\n",
      "2863    8100\n",
      "2873    5777\n",
      "2885    6627\n",
      "2896    4434\n",
      "2925   12700\n",
      "\n",
      "[246 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "selected_columns = ['K'] #['K','Erreur'] when I only consider K, the model gets significanntly better, idk why?\n",
    "X = x_train[selected_columns]\n",
    "\n",
    "# 2. Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.005, min_samples=9)  # The more eps is lower and min_samples is bigger, the more outliers you get, play with these parameters until you find the best outliers possible to delete\n",
    "labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# 4. Identify outliers\n",
    "x_train['Cluster'] = labels\n",
    "outliers = x_train[x_train['Cluster'] == -1]\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(x_train.shape)\n",
    "print(\"\\nOutliers:\")\n",
    "print(outliers[['K']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "565d13f7-4ec5-410d-9ca8-80f2d1e625b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "# # Data preparation\n",
    "# selected_columns = ['K']\n",
    "# X = x_train[selected_columns]\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Parameter grid\n",
    "# eps_values = np.linspace(0.05, 1.0, 10)  # Range of epsilon values\n",
    "# min_samples_values = [3, 5, 10, 20]  # Different min_samples\n",
    "# best_params = None\n",
    "# best_score = -1\n",
    "\n",
    "# # Iterate through the parameter grid\n",
    "# for eps in eps_values:\n",
    "#     for min_samples in min_samples_values:\n",
    "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "#         labels = dbscan.fit_predict(X_scaled)\n",
    "        \n",
    "#         # Only evaluate if we have more than 1 cluster\n",
    "#         if len(set(labels)) > 1:\n",
    "#             score = silhouette_score(X_scaled, labels)\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "# print(\"Best Parameters:\", best_params)\n",
    "# print(\"Best Silhouette Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e6412fde-2f28-452f-83ad-b6bd7370bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[x_train['Cluster']!=-1].drop(['Cluster'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cf6b4b8b-e513-45a6-a6f7-d7f22b5481df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_outliers_iqr(data, column):\n",
    "#     # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "#     Q1 = data[column].quantile(0.25)\n",
    "#     Q3 = data[column].quantile(0.75)\n",
    "    \n",
    "#     # Calculate IQR\n",
    "#     IQR = Q3 - Q1\n",
    "    \n",
    "#     # Define lower and upper bounds\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "#     # Identify outliers\n",
    "#     not_outliers = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "    \n",
    "#     return not_outliers, lower_bound, upper_bound\n",
    "\n",
    "# # Call the function\n",
    "# not_outliers, lower_bound, upper_bound = detect_outliers_iqr(x_train, 'K')\n",
    "\n",
    "# # Print results\n",
    "# print(\"Outliers:\")\n",
    "# print(not_outliers['K'].shape)\n",
    "# print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "207c3c56-9d8b-4345-8799-0d3569f12e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = not_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2214c4ec-fe19-4b5d-9392-c89868eee5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].isnull()==False,\"logK\"]) - x_train.loc[x_train[\"logK\"].isnull()==False,\"K\"])/10\n",
    "x_train.loc[x_train[\"Erreur\"].isnull()==True,\"Erreur\"] =Erreur\n",
    "x_test.loc[x_test[\"Erreur\"].isnull()==True,\"Erreur\"] =x_train[\"Erreur\"].mean() ##verifier si l'approche marche ou nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8074bc8a-1bbb-431d-900b-1afde76c7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train['K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "be4ee797-52cb-4def-bf6d-d1de1cc091b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['Original_Value','Guest',\"Reference\",\"CID_Guest\",\"IsomericSMILES_Host\",\"IsomericSMILES\",'Charge_Host','K','logK'],axis=1)\n",
    "x_test = dataset_test.drop(['Original_Value','Guest',\"Reference\",\"CID_Guest\",\"IsomericSMILES_Host\",\"IsomericSMILES\",'Charge_Host'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aeda8cc5-6f27-4ccc-8152-e340e250dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "categorical_columns = [\"Host\"] \n",
    "Onehot = [\"Host\"]\n",
    "label_encoder = [] \n",
    "for col in label_encoder:\n",
    "    x_train[col] = LabelEncoder().fit_transform(x_train[col])\n",
    "remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\"),Onehot)],remainder='passthrough')\n",
    "x_train_array = ct.fit_transform(x_train)\n",
    "encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "x_train = pd.DataFrame(x_train_array, columns=all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f3316404-98ab-43c6-9656-9ad2a20402e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_array = ct.transform(x_test)\n",
    "for col in label_encoder:\n",
    "    x_test[col] = LabelEncoder().fit_transform(x_test[col])\n",
    "encoded_feature_names_test = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "all_feature_names_test = list(encoded_feature_names_test) + remainder_cols\n",
    "x_test = pd.DataFrame(x_test_array, columns=all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fd38dde5-04bf-4829-8f94-58a59e6363ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, Gamma, n_est, md, sub, col, Rega, Regl =  [0.01, 0.01, 400, 11, 0.6, 0.8, 0.1, 1.5]\n",
    "best_params = {\"learning_rate\" : lr, \n",
    "               \"gamma\" : Gamma, \n",
    "               \"n_estimators\" : n_est, \n",
    "                \"max_depth\":md,\n",
    "                \"reg_lambda\":Regl,\n",
    "               \"reg_alpha\":Rega,\n",
    "               \"subsample\":sub,\n",
    "               \"colsample_bytree\":col,\n",
    "              \"booster\" : 'gbtree', \n",
    "              \"random_state\":42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "438221f3-b5b8-4932-bce3-23ad68026c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XG_reg = XGBRegressor(\n",
    "    \n",
    "    # gamma = 0.01,\n",
    "    # learning_rate = 0.01,\n",
    "    # n_estimators=800,\n",
    "    # random_state=42,\n",
    "    # max_depth=6,\n",
    "    # reg_lambda = 1.3,\n",
    "    # reg_alpha=0.4\n",
    "    # learning_rate = 0.01, \n",
    "    # gamma = 0.01, \n",
    "    # n_estimators =600, \n",
    "    # max_depth = 11,\n",
    "    # reg_lambda=1.5,\n",
    "    # reg_alpha =0.1,\n",
    "    # subsample = 0.6,\n",
    "    # colsample_bytree = 0.8,\n",
    "    # booster = 'gbtree', \n",
    "    # random_state= 42\n",
    "    **best_params\n",
    ")  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "caddbfc2-b4ca-409a-9b54-3486471d78ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Scores: [279.67965422 287.75215786 264.21127211 291.36249164 307.80481391]\n",
      "Mean MAE Score: 286.16207794720265 (+/- 14.295736224150584)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# K-fold cross validation\n",
    "scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=5,scoring = 'neg_mean_absolute_error')  # 5-fold CV is relevant to get an idea of the model's performance\n",
    "print(f\"MAE Scores: {-scores}\")\n",
    "print(f\"Mean MAE Score: {-scores.mean()} (+/- {scores.std()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "49a18aeb-9be5-4931-8767-750a7c8e6b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Scores: [501.96307357 523.5021383  450.81351382 514.92949551 487.53235331]\n",
      "Mean RMSE Score: 495.748114902057 (+/- 25.547814001933972)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=5,scoring = 'neg_mean_squared_error') # 5-fold CV is relevant to get an idea of the model's performance\n",
    "scores = np.sqrt(-scores)\n",
    "print(f\"RMSE Scores: {scores}\")\n",
    "print(f\"Mean RMSE Score: {scores.mean()} (+/- {scores.std()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c93061f9-7ebc-4ec4-b5a3-ee13592b77ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [0.56927621 0.54460979 0.64051783 0.55868328 0.58224601]\n",
      "Mean CV Score: 0.579 (+/- 0.066)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# K-fold cross validation\n",
    "scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=5,scoring = 'r2')  # 5-fold CV is relevant to get an idea of the model's performance\n",
    "print(f\"CV Scores: {scores}\")\n",
    "print(f\"Mean CV Score: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "79b6f2fc-5759-4239-b516-2ce87fb766ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.0, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.0, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=0.0, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XG_reg.fit(x_train.values,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "828cbe62-0c60-45de-9931-a8c2f0d6cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = XG_reg.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "caeb6097-2386-4f62-9be2-8fe375943be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host</th>\n",
       "      <th>CID_Host</th>\n",
       "      <th>Guest</th>\n",
       "      <th>CID_Guest</th>\n",
       "      <th>pH</th>\n",
       "      <th>T</th>\n",
       "      <th>Erreur</th>\n",
       "      <th>K</th>\n",
       "      <th>logK</th>\n",
       "      <th>Reference</th>\n",
       "      <th>...</th>\n",
       "      <th>iso2vec-host-1</th>\n",
       "      <th>iso2vec-host-2</th>\n",
       "      <th>iso2vec-host-3</th>\n",
       "      <th>iso2vec-host-4</th>\n",
       "      <th>iso2vec-host-5</th>\n",
       "      <th>iso2vec-host-6</th>\n",
       "      <th>iso2vec-host-7</th>\n",
       "      <th>iso2vec-host-8</th>\n",
       "      <th>iso2vec-host-9</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>beta-cyclodextrin</td>\n",
       "      <td>444041</td>\n",
       "      <td>bdbm36146</td>\n",
       "      <td>3769791.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J Am Chem Soc 115: 475-481 (1993)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864454</td>\n",
       "      <td>0.300333</td>\n",
       "      <td>-0.063001</td>\n",
       "      <td>0.331219</td>\n",
       "      <td>0.153562</td>\n",
       "      <td>0.612107</td>\n",
       "      <td>-0.280278</td>\n",
       "      <td>-0.228449</td>\n",
       "      <td>-0.048585</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Host  CID_Host      Guest  CID_Guest   pH      T  Erreur  \\\n",
       "875  beta-cyclodextrin    444041  bdbm36146  3769791.0  7.2  298.0     0.0   \n",
       "\n",
       "          K  logK                          Reference  ... iso2vec-host-1  \\\n",
       "875  234423   NaN  J Am Chem Soc 115: 475-481 (1993)  ...       0.864454   \n",
       "\n",
       "    iso2vec-host-2 iso2vec-host-3  iso2vec-host-4  iso2vec-host-5  \\\n",
       "875       0.300333      -0.063001        0.331219        0.153562   \n",
       "\n",
       "     iso2vec-host-6  iso2vec-host-7  iso2vec-host-8  iso2vec-host-9  Cluster  \n",
       "875        0.612107       -0.280278       -0.228449       -0.048585       -1  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[dataset_train['K']>234420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0d5b2b6a-b412-48ab-aff9-6770891f2c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ed582afc-11da-4db8-9d82-e41cc8599789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.6674943, 4.046828 , 5.963834 , 4.784194 , 6.0868964, 3.7318652,\n",
       "       6.3807187, 7.7454553, 5.411765 , 5.7077985, 6.3024964, 5.9138517,\n",
       "       6.293907 , 6.523822 , 5.6041403, 5.148795 , 6.449853 , 6.1388755,\n",
       "       5.092592 , 4.878553 , 5.5319414, 6.3723683, 5.2702193, 4.5220413,\n",
       "       6.2149715, 4.355862 , 6.416643 , 5.1888375, 7.030398 , 6.428417 ,\n",
       "       7.032764 , 4.2762456, 6.892796 , 5.706357 , 6.993309 , 3.469652 ,\n",
       "       7.332748 , 7.8686075, 7.3301   , 6.647184 , 6.861958 , 6.1200767,\n",
       "       5.6495194, 4.1219325, 5.6547756, 6.3506145, 6.2798305, 4.7966604,\n",
       "       5.2912016, 4.4106493, 6.3316417, 6.3619432, 6.7077274, 6.2143497,\n",
       "       5.8256545, 5.515854 , 5.943386 , 4.6041775, 5.5953135, 6.4643373,\n",
       "       5.1434813, 6.32401  , 6.0921373, 6.0163226, 5.879352 , 5.030753 ,\n",
       "       7.2401505, 6.11217  , 4.046828 , 4.448993 , 7.971345 , 5.747526 ,\n",
       "       6.3912783, 6.565766 , 6.4320936, 7.120037 , 6.0021124, 5.5749307,\n",
       "       5.809621 , 6.765387 , 5.3731556, 5.802165 , 5.9928145, 3.8791127,\n",
       "       4.260811 , 5.119026 , 6.133669 , 6.5978804, 6.5693483, 5.752995 ,\n",
       "       4.375058 , 4.3275146, 4.3767357, 6.179508 , 7.0099916, 5.7291727,\n",
       "       5.1187835, 4.9463806, 6.544629 , 6.293642 , 5.8312335, 6.0907054,\n",
       "       8.176234 , 6.7929983, 3.957282 , 3.8971274, 6.1998124, 4.426903 ,\n",
       "       6.6656675, 6.0280123, 5.4598017, 6.3258615, 3.6343536, 5.3040566,\n",
       "       6.3745255, 6.3788166, 4.3806887, 6.1800094, 5.247983 , 5.730895 ,\n",
       "       4.2035604, 6.2942777, 6.281964 , 6.094808 , 5.7401304, 6.113888 ,\n",
       "       6.438924 , 5.6018004, 6.7645183, 4.05487  , 6.2109213, 5.7034793,\n",
       "       6.3271694, 5.494163 , 6.7682385, 4.801448 , 6.176857 , 6.4252715,\n",
       "       5.798771 , 6.6124444, 6.3863273, 6.032939 , 5.2852287, 5.726183 ,\n",
       "       4.6996064, 4.564125 , 6.4338875, 5.463996 , 4.6999993, 6.1654544,\n",
       "       6.452028 , 5.21526  , 6.491752 , 7.3840756, 3.4619055, 6.461389 ,\n",
       "       5.8902254, 6.022034 , 6.3532605, 3.5537267, 5.483856 , 6.8257847,\n",
       "       6.638984 , 7.3164763, 5.6311054, 5.7189283, 5.4397097, 5.2750206,\n",
       "       5.632565 , 6.413636 , 4.9921613, 7.8214045, 5.0497127, 6.672422 ,\n",
       "       6.3143234, 5.6457157, 5.166588 , 6.5224595, 5.8809023, 6.017331 ,\n",
       "       5.3091526, 6.5520134, 6.3149147, 6.152863 , 6.974778 , 5.271335 ,\n",
       "       5.0779014, 5.066973 , 6.6102104, 3.495091 , 6.260805 , 5.3870497,\n",
       "       4.3678465, 6.5438104, 5.1884375, 4.3033776, 3.8087323, 6.7470074,\n",
       "       6.584055 , 6.178251 , 6.264994 , 6.0794   , 5.6101327, 6.105968 ,\n",
       "       5.459629 , 7.0332155, 6.7994633, 5.6932807, 5.372124 , 5.5108385,\n",
       "       5.32265  , 6.3133407, 4.478293 , 6.497241 , 4.7611217, 4.1075697,\n",
       "       6.9746647, 5.630783 , 6.063139 , 7.8113384, 7.7061605, 5.980215 ,\n",
       "       4.752417 , 6.7285666, 3.421936 , 6.5639358, 5.589362 , 4.281619 ,\n",
       "       5.1384945, 6.1860833, 6.818527 , 5.7171736, 7.2492495, 5.2947392,\n",
       "       5.456584 , 5.8435063, 6.4746914, 6.0324125, 5.50434  , 4.722562 ,\n",
       "       4.9819794, 5.456148 , 5.905177 , 6.4565563, 6.337362 , 6.121637 ,\n",
       "       5.5686555, 3.1248066, 4.998585 , 5.614645 , 6.137126 , 6.1864786,\n",
       "       5.7548885, 5.3873253, 4.734331 , 4.016374 , 4.7096977, 4.8474298,\n",
       "       6.676688 , 6.6522145, 4.1423087, 5.7820354, 6.04591  , 5.3888707,\n",
       "       5.8746667, 5.8503027, 6.4367466, 5.9405336, 5.961949 , 4.750116 ,\n",
       "       6.663893 , 5.670699 , 4.7283525, 5.6492243, 6.65534  , 6.440688 ,\n",
       "       6.3082757, 5.1407237, 5.2227364, 5.3988194, 5.4459143, 3.8624911,\n",
       "       6.228268 , 6.232939 , 5.427842 , 6.5519385, 6.317869 , 7.6175685,\n",
       "       6.486862 , 6.310366 , 7.1023808, 7.1767187, 6.261632 , 6.6413417,\n",
       "       6.5773916, 5.991349 , 4.5454793, 6.661641 , 5.2376413, 6.3974657,\n",
       "       7.0187197, 5.2303376, 6.413847 , 4.6364875, 5.73942  , 7.503694 ,\n",
       "       7.055157 , 7.535524 , 6.6720915, 7.3417096, 3.9674993, 5.971305 ,\n",
       "       6.540247 , 7.1557975, 6.751542 , 5.1334486, 5.327107 , 5.759909 ,\n",
       "       6.6672544, 7.189449 , 5.754592 , 6.4640603, 6.80449  , 4.4955473,\n",
       "       5.8263197, 6.1043878, 4.7946124, 5.9733586, 6.3074455, 5.7584105,\n",
       "       6.0402193, 6.23435  , 6.75884  , 6.055147 , 6.7187757, 5.7049026,\n",
       "       5.297231 , 5.504975 , 6.756381 , 6.477176 , 6.392291 , 3.894382 ,\n",
       "       4.2705045, 5.8060756, 5.4664707, 6.6626177, 6.0211034, 6.5353894,\n",
       "       5.336465 , 6.7444305, 6.9969873, 5.929491 , 6.386943 , 4.358694 ,\n",
       "       4.805569 , 5.871625 , 6.407529 , 5.8964524, 6.8444757, 6.069988 ,\n",
       "       6.824174 , 6.72022  , 6.952559 , 6.172798 , 4.5220246, 5.9950023,\n",
       "       5.832716 , 4.6261597, 6.190949 , 5.4514923, 5.8727517, 4.6279626,\n",
       "       5.819514 , 4.780195 , 4.7513204, 3.6632788, 4.6118817, 5.785418 ,\n",
       "       6.601957 , 5.058174 , 4.6645966, 4.0447264, 5.8591633, 6.26916  ,\n",
       "       3.6323965, 5.0974436, 6.826493 , 5.6883097, 6.3688364, 5.85815  ,\n",
       "       6.6865506, 4.184957 , 4.9295516, 5.743142 , 4.8280745, 6.8656445,\n",
       "       5.127649 , 4.841594 , 6.505502 , 5.3062134, 5.4349556, 5.3466825,\n",
       "       6.194437 , 5.4051948, 6.154791 , 6.1398335, 6.0292826, 6.1276855,\n",
       "       5.999214 , 5.9935617, 4.0424423, 6.0939846, 7.4688025, 5.30707  ,\n",
       "       6.3297677, 5.165477 , 5.86171  , 5.6233397, 4.0340605, 5.279792 ,\n",
       "       5.38557  , 6.395014 , 6.378039 , 6.3278666, 6.154121 , 3.715685 ,\n",
       "       4.1909547, 5.810106 , 5.764616 , 6.6805534, 7.0088277, 5.4723034,\n",
       "       5.4257812, 6.647847 , 6.6150646, 5.293724 , 4.452658 , 6.288121 ,\n",
       "       6.6867876, 6.5890026, 5.677412 , 6.594011 , 5.8874655, 6.19901  ,\n",
       "       6.510029 , 7.062537 , 6.072867 , 5.6404796, 5.1818924, 7.2990265,\n",
       "       7.8137574, 5.5524707, 6.403276 , 5.857605 , 6.3632646, 4.2175307,\n",
       "       5.4026484, 7.649781 , 5.2837944, 5.582541 , 4.746505 , 6.3318963,\n",
       "       3.7539752, 5.1627645, 1.2094244, 4.9779015, 4.235552 , 5.816928 ,\n",
       "       6.9273987, 6.941204 , 5.730522 , 6.138121 , 5.5559626, 3.3839014,\n",
       "       7.3885307, 6.459066 , 6.5248723, 5.7525463, 5.9820304, 5.7148275,\n",
       "       4.711807 , 5.5874467, 6.6125546, 6.6667743, 5.6851377, 6.118654 ,\n",
       "       5.043897 , 6.8167286, 2.341644 , 6.957583 , 4.270048 , 6.670491 ,\n",
       "       6.8696647, 5.2015185, 5.5522103, 7.1898417, 5.2313423, 5.271873 ,\n",
       "       5.2495475, 3.34952  , 6.637007 , 6.128311 , 5.718344 , 6.765566 ,\n",
       "       6.2107453, 4.4099517, 3.425179 , 5.7428803, 5.5071826, 3.4803417,\n",
       "       4.639077 , 6.363243 , 4.784222 , 5.013417 , 6.7462707, 6.859018 ,\n",
       "       6.133119 , 6.8038497, 6.2193913], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "455b0505-d367-4096-8426-02eb914022ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.02689655, 0.0437931 , 0.06068966, 0.07758621,\n",
       "       0.09448276, 0.11137931, 0.12827586, 0.14517241, 0.16206897,\n",
       "       0.17896552, 0.19586207, 0.21275862, 0.22965517, 0.24655172,\n",
       "       0.26344828, 0.28034483, 0.29724138, 0.31413793, 0.33103448,\n",
       "       0.34793103, 0.36482759, 0.38172414, 0.39862069, 0.41551724,\n",
       "       0.43241379, 0.44931034, 0.4662069 , 0.48310345, 0.5       ])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.01,0.5,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "79a6e4f1-1a0f-49d8-821d-b21acdd59d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "L = [1,2,3]\n",
    "T = [0.1,0.2,0.3]\n",
    "S = [0.001,0.5]\n",
    "combination = itertools.product(L,T,S)\n",
    "for c in combination:\n",
    "    print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1b3ccb05-0b8f-4b8a-abd1-8856bb0941fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# def fine_tune_DBSCAN(dataset_train):\n",
    "#         L_R = np.linspace(0.01,0.5,30),     # Test different learning rates\n",
    "#         gamma = np.linspace(0,3,30)\n",
    "#         N_estimators = [50,100, 200,400,600,800,1000,1200],              # Number of boosting rounds\n",
    "#         MDepth =  [i for i in range(2,12)],                   # Depth of trees\n",
    "#         SUBSAMPLE = [0.6, 0.8, 1.0],                # Fraction of samples used per tree\n",
    "#         COLSAMPLE_BYTREE = [0.6, 0.8, 1.0],         # Fraction of features used per tree\n",
    "#         REG_ALPHA = [0, 0.1, 1],                    # L1 regularization\n",
    "#         REG_LAMBDA = [1, 1.5, 2]                    # L2 regularization\n",
    "#         eps_values = np.linspace(0.005, 1.0, 10)  # Range of epsilon values\n",
    "#         min_samples_values = [2,3,5,10]  # Different min_samples\n",
    "#         best_score = 0\n",
    "#         best_params = [0,0]\n",
    "#         best_score_xg = 0\n",
    "#         combination = itertools.product(L_R,gamma,N_estimators,MDepth,SUBSAMPLE,COLSAMPLE_BYTREE,REG_ALPHA,REG_LAMBDA)\n",
    "#         for eps_val in eps_values:\n",
    "#             for sample in min_samples_values:\n",
    "#                 x_train = dataset_train\n",
    "#                 selected_columns = ['K'] #['K','Erreur'] when I only consider K, the model gets significanntly better, idk why?\n",
    "#                 X = x_train[selected_columns]\n",
    "                \n",
    "#                 # 2. Scale the data\n",
    "#                 scaler = StandardScaler()\n",
    "#                 X_scaled = scaler.fit_transform(X)\n",
    "                \n",
    "#                 # 3. Apply DBSCAN\n",
    "#                 dbscan = DBSCAN(eps=eps_val, min_samples=sample)  # The more eps is lower and min_samples is bigger, the more outliers you get, play with these parameters until you find the best outliers possible to delete\n",
    "#                 labels = dbscan.fit_predict(X_scaled)\n",
    "                \n",
    "#                 # 4. Identify outliers\n",
    "#                 x_train['Cluster'] = labels\n",
    "#                 outliers = x_train[x_train['Cluster'] == -1]\n",
    "#                 x_train = x_train[x_train['Cluster']!=-1].drop(['Cluster'],axis=1)\n",
    "#                 Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].isnull()==False,\"logK\"]) - x_train.loc[x_train[\"logK\"].isnull()==False,\"K\"])/10\n",
    "#                 x_train.loc[x_train[\"Erreur\"].isnull()==True,\"Erreur\"] =Erreur\n",
    "#                 y_train = x_train['K']\n",
    "#                 x_train = x_train.drop(['Original_Value','Guest',\"Reference\",\"CID_Guest\",\"IsomericSMILES_Host\",\"IsomericSMILES\",'Charge_Host','K','logK'],axis=1)\n",
    "#                 categorical_columns = [\"Host\"] \n",
    "#                 Onehot = [\"Host\"]\n",
    "#                 label_encoder = [] \n",
    "#                 for col in label_encoder:\n",
    "#                     x_train[col] = LabelEncoder().fit_transform(x_train[col])\n",
    "#                 remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "#                 ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\"),Onehot)],remainder='passthrough')\n",
    "#                 x_train_array = ct.fit_transform(x_train)\n",
    "#                 encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "#                 all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "#                 x_train = pd.DataFrame(x_train_array, columns=all_feature_names)\n",
    "#                 XG_reg = XGBRegressor(\n",
    "#                 booster = 'gbtree',   \n",
    "#                 # gamma = 0.01,\n",
    "#                  learning_rate = 0.01,\n",
    "#                  n_estimators=800,\n",
    "#                  random_state=42,\n",
    "#                  max_depth=6,\n",
    "#                 # reg_lambda = 1.3,\n",
    "#                 # reg_alpha=0.4\n",
    "#                 ) \n",
    "#                 scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=5,scoring = 'r2')  # 5-fold CV is relevant to get an idea of the model's performance\n",
    "#                 print(scores)\n",
    "#                 print(\"this is eps:\", eps_val,\"this is sample:\",sample)\n",
    "#                 if(best_score<scores.mean()):\n",
    "#                     best_score = scores.mean()\n",
    "#                     best_params = [eps_val,sample]\n",
    "#         x_train = dataset_train\n",
    "#         selected_columns = ['K'] #['K','Erreur'] when I only consider K, the model gets significanntly better, idk why?\n",
    "#         X = x_train[selected_columns]\n",
    "        \n",
    "#         # 2. Scale the data\n",
    "#         scaler = StandardScaler()\n",
    "#         X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "#         # 3. Apply DBSCAN\n",
    "#         dbscan = DBSCAN(eps=best_params[0], min_samples=best_params[1])  # The more eps is lower and min_samples is bigger, the more outliers you get, play with these parameters until you find the best outliers possible to delete\n",
    "#         labels = dbscan.fit_predict(X_scaled)\n",
    "        \n",
    "#         # 4. Identify outliers\n",
    "#         x_train['Cluster'] = labels\n",
    "#         outliers = x_train[x_train['Cluster'] == -1]\n",
    "#         x_train = x_train[x_train['Cluster']!=-1].drop(['Cluster'],axis=1)\n",
    "#         Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].isnull()==False,\"logK\"]) - x_train.loc[x_train[\"logK\"].isnull()==False,\"K\"])/10\n",
    "#         x_train.loc[x_train[\"Erreur\"].isnull()==True,\"Erreur\"] =Erreur\n",
    "#         y_train = x_train['K']\n",
    "#         x_train = x_train.drop(['Original_Value','Guest',\"Reference\",\"CID_Guest\",\"IsomericSMILES_Host\",\"IsomericSMILES\",'Charge_Host','K','logK'],axis=1)\n",
    "#         categorical_columns = [\"Host\"] \n",
    "#         Onehot = [\"Host\"]\n",
    "#         label_encoder = [] \n",
    "#         for col in label_encoder:\n",
    "#             x_train[col] = LabelEncoder().fit_transform(x_train[col])\n",
    "#         remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "#         ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\"),Onehot)],remainder='passthrough')\n",
    "#         x_train_array = ct.fit_transform(x_train)\n",
    "#         encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "#         all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "#         x_train = pd.DataFrame(x_train_array, columns=all_feature_names)\n",
    "#         for lr,Gamma,n_est,md,sub,col,Rega,Regl in combination:\n",
    "#             XG_reg = XGBRegressor(\n",
    "#                 booster = 'gbtree',   \n",
    "#                 gamma = Gamma,\n",
    "#                 learning_rate = lr,\n",
    "#                 n_estimators=n_est,\n",
    "#                 random_state=42,\n",
    "#                 max_depth=md,\n",
    "#                 reg_lambda = Regl,\n",
    "#                 reg_alpha=Rega,\n",
    "#                 subsample = sub,\n",
    "#                 colsample_bytree=col\n",
    "#                 ) \n",
    "#             scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=3,scoring = 'r2')\n",
    "#             if(scores.mean()>best_score_xg):\n",
    "#                 best_score_xg = scores.mean()\n",
    "#                 best_params_xg = [lr,Gamma,n_est,md,sub,col,Rega,Regl]\n",
    "#                 print(\"this is best score :\",best_params_xg)\n",
    "#                 print(\"for the following params:\",best_params_xg)\n",
    "#         return best_score,best_params,best_score_xg,best_params_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9dc583e7-f67c-4b3e-83ca-be374c943dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "import itertools\n",
    "\n",
    "def fine_tune_DBSCAN(dataset_train):\n",
    "    # Define hyperparameter ranges\n",
    "    L_R = np.linspace(0.01, 0.5, 30)  # Learning rates\n",
    "    gamma = np.linspace(0, 3, 30)  # Gamma values\n",
    "    N_estimators = [50, 100, 200, 400, 600, 800, 1000, 1200]  # Boosting rounds\n",
    "    MDepth = list(range(2, 12))  # Depth of trees\n",
    "    SUBSAMPLE = [0.6, 0.8, 1.0]  # Subsample rates\n",
    "    COLSAMPLE_BYTREE = [0.6, 0.8, 1.0]  # Feature subsample rates\n",
    "    REG_ALPHA = [0, 0.1, 1]  # L1 regularization\n",
    "    REG_LAMBDA = [1, 1.5, 2]  # L2 regularization\n",
    "    eps_values = np.linspace(0.005, 1.0, 30)  # Epsilon values\n",
    "    min_samples_values = list(range(2, 12))  # Minimum samples for DBSCAN\n",
    "\n",
    "    best_score = 0\n",
    "    best_params = [0, 0]\n",
    "    best_score_xg = 0\n",
    "    best_params_xg = None\n",
    "\n",
    "    # Generate combinations of XGBoost parameters\n",
    "    combinations = itertools.product(L_R, gamma, N_estimators, MDepth, SUBSAMPLE, COLSAMPLE_BYTREE, REG_ALPHA, REG_LAMBDA)\n",
    "\n",
    "    for eps_val in eps_values:\n",
    "        for sample in min_samples_values:\n",
    "            x_train = dataset_train.copy()\n",
    "            selected_columns = ['K']\n",
    "            X = x_train[selected_columns]\n",
    "            \n",
    "            # Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Apply DBSCAN\n",
    "            dbscan = DBSCAN(eps=eps_val, min_samples=sample)\n",
    "            labels = dbscan.fit_predict(X_scaled)\n",
    "            \n",
    "            # Identify outliers and filter the dataset\n",
    "            x_train['Cluster'] = labels\n",
    "            x_train = x_train[x_train['Cluster'] != -1].drop(['Cluster'], axis=1)\n",
    "            \n",
    "            # Calculate Error\n",
    "            Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].notnull(), \"logK\"]) - \n",
    "                            x_train.loc[x_train[\"logK\"].notnull(), \"K\"]) / 10\n",
    "            x_train.loc[x_train[\"Erreur\"].isnull(), \"Erreur\"] = Erreur\n",
    "            y_train = x_train['K']\n",
    "            x_train = x_train.drop(['Original_Value', 'Guest', \"Reference\", \"CID_Guest\", \"IsomericSMILES_Host\",\n",
    "                                    \"IsomericSMILES\", 'Charge_Host', 'K', 'logK'], axis=1)\n",
    "            \n",
    "            # Encode categorical variables\n",
    "            categorical_columns = [\"Host\"]\n",
    "            Onehot = [\"Host\"]\n",
    "            ct = ColumnTransformer(\n",
    "                transformers=[('encoder', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), Onehot)],\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "            x_train_array = ct.fit_transform(x_train)\n",
    "            encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "            remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "            all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "            x_train = pd.DataFrame(x_train_array, columns=all_feature_names)\n",
    "            \n",
    "            # Evaluate model with cross-validation\n",
    "            XG_reg = XGBRegressor(\n",
    "                booster='gbtree',\n",
    "                learning_rate=0.01,\n",
    "                n_estimators=800,\n",
    "                random_state=42,\n",
    "                max_depth=6\n",
    "            )\n",
    "            scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=5, scoring='r2')\n",
    "            print(f\"Scores: {scores}, eps: {eps_val}, min_samples: {sample}\")\n",
    "            if best_score < scores.mean():\n",
    "                best_score = scores.mean()\n",
    "                best_params = [eps_val, sample]\n",
    "\n",
    "    # # Final DBSCAN with best parameters\n",
    "    # x_train = dataset_train.copy()\n",
    "    # X = x_train[selected_columns]\n",
    "    # scaler = StandardScaler()\n",
    "    # X_scaled = scaler.fit_transform(X)\n",
    "    # dbscan = DBSCAN(eps=best_params[0], min_samples=best_params[1])\n",
    "    # labels = dbscan.fit_predict(X_scaled)\n",
    "    # x_train['Cluster'] = labels\n",
    "    # x_train = x_train[x_train['Cluster'] != -1].drop(['Cluster'], axis=1)\n",
    "    # Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].notnull(), \"logK\"]) - \n",
    "    #                 x_train.loc[x_train[\"logK\"].notnull(), \"K\"]) / 10\n",
    "    # x_train.loc[x_train[\"Erreur\"].isnull(), \"Erreur\"] = Erreur\n",
    "    # y_train = x_train['K']\n",
    "    # x_train = x_train.drop(['Original_Value', 'Guest', \"Reference\", \"CID_Guest\", \"IsomericSMILES_Host\",\n",
    "    #                         \"IsomericSMILES\", 'Charge_Host', 'K', 'logK'], axis=1)\n",
    "    # categorical_columns = [\"Host\"]\n",
    "    # ct = ColumnTransformer(\n",
    "    #     transformers=[('encoder', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), Onehot)],\n",
    "    #     remainder='passthrough'\n",
    "    # )\n",
    "    # x_train_array = ct.fit_transform(x_train)\n",
    "    # encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "    # remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "    # all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "    # x_train = pd.DataFrame(x_train_array, columns=all_feature_names)\n",
    "    \n",
    "    # # Fine-tune XGBoost\n",
    "    # for lr, Gamma, n_est, md, sub, col, Rega, Regl in combinations:\n",
    "    #     XG_reg = XGBRegressor(\n",
    "    #         booster='gbtree',\n",
    "    #         gamma=Gamma,\n",
    "    #         learning_rate=lr,\n",
    "    #         n_estimators=n_est,\n",
    "    #         random_state=42,\n",
    "    #         max_depth=md,\n",
    "    #         reg_lambda=Regl,\n",
    "    #         reg_alpha=Rega,\n",
    "    #         subsample=sub,\n",
    "    #         colsample_bytree=col\n",
    "    #     )\n",
    "    #     scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=3, scoring='r2')\n",
    "    #     if scores.mean() > best_score_xg:\n",
    "    #         best_score_xg = scores.mean()\n",
    "    #         best_params_xg = [lr, Gamma, n_est, md, sub, col, Rega, Regl]\n",
    "    #         print(f\"Best Score: {best_score_xg}, Params: {best_params_xg}\")\n",
    "\n",
    "    return best_score, best_params #, best_score_xg, best_params_xg\n",
    "##Early stopped because the code might take to 34 days to colmplete HHHHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3b13e52b-c2d0-4794-817d-128b92beedf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.14997065 0.96909994 0.41319847 0.06014425 0.39447373], eps: 0.005, min_samples: 2\n",
      "Scores: [0.4434045  0.4002561  0.46218526 0.45189971 0.46077603], eps: 0.005, min_samples: 3\n",
      "Scores: [0.40436822 0.41689187 0.46293515 0.5911696  0.4882918 ], eps: 0.005, min_samples: 4\n",
      "Scores: [0.58261323 0.48274761 0.58553183 0.59383214 0.48867476], eps: 0.005, min_samples: 5\n",
      "Scores: [0.56922877 0.48300272 0.55187285 0.57108557 0.5050016 ], eps: 0.005, min_samples: 6\n",
      "Scores: [0.55427468 0.45818979 0.64619124 0.54175258 0.46015364], eps: 0.005, min_samples: 7\n",
      "Scores: [0.52532887 0.45715863 0.65867949 0.57440364 0.47494191], eps: 0.005, min_samples: 8\n",
      "Scores: [0.54632008 0.52444392 0.62608314 0.53201556 0.55556703], eps: 0.005, min_samples: 9\n",
      "Scores: [0.53611881 0.4925195  0.59646559 0.47985798 0.5513044 ], eps: 0.005, min_samples: 10\n",
      "Scores: [0.51116431 0.49291873 0.59088403 0.46017957 0.5548296 ], eps: 0.005, min_samples: 11\n",
      "Scores: [-0.01248646  0.94375193  0.41860342  0.07198632  0.36573321], eps: 0.039310344827586205, min_samples: 2\n",
      "Scores: [0.29554969 0.24151289 0.32906532 0.31665212 0.3707903 ], eps: 0.039310344827586205, min_samples: 3\n",
      "Scores: [0.37945485 0.41360962 0.35539514 0.37348133 0.47410333], eps: 0.039310344827586205, min_samples: 4\n",
      "Scores: [0.38091564 0.4386459  0.38335299 0.41838467 0.46976835], eps: 0.039310344827586205, min_samples: 5\n",
      "Scores: [0.3454923  0.37582999 0.38410616 0.48925722 0.46824044], eps: 0.039310344827586205, min_samples: 6\n",
      "Scores: [0.46656591 0.37162238 0.44037813 0.55609262 0.48173541], eps: 0.039310344827586205, min_samples: 7\n",
      "Scores: [0.46493822 0.47126794 0.43925822 0.53744173 0.42047483], eps: 0.039310344827586205, min_samples: 8\n",
      "Scores: [0.45517105 0.37988609 0.54081511 0.58354652 0.48536396], eps: 0.039310344827586205, min_samples: 9\n",
      "Scores: [0.45517105 0.37988609 0.54081511 0.58354652 0.48536396], eps: 0.039310344827586205, min_samples: 10\n",
      "Scores: [0.44471323 0.43789077 0.53046656 0.59874547 0.49577475], eps: 0.039310344827586205, min_samples: 11\n",
      "Scores: [-0.00783861  0.93876034  0.41166741  0.06456983  0.40568292], eps: 0.07362068965517242, min_samples: 2\n",
      "Scores: [0.07749844 0.37858438 0.38343596 0.39992374 0.48907894], eps: 0.07362068965517242, min_samples: 3\n",
      "Scores: [0.32741058 0.41366792 0.433249   0.43381172 0.4240554 ], eps: 0.07362068965517242, min_samples: 4\n",
      "Scores: [0.36632586 0.31635177 0.45287818 0.34516674 0.43877333], eps: 0.07362068965517242, min_samples: 5\n",
      "Scores: [0.36632586 0.31635177 0.45287818 0.34516674 0.43877333], eps: 0.07362068965517242, min_samples: 6\n",
      "Scores: [0.36632586 0.31635177 0.45287818 0.34516674 0.43877333], eps: 0.07362068965517242, min_samples: 7\n",
      "Scores: [0.3860206  0.28896511 0.44651109 0.38233399 0.47489858], eps: 0.07362068965517242, min_samples: 8\n",
      "Scores: [0.42633659 0.45607293 0.43886638 0.54834509 0.5410763 ], eps: 0.07362068965517242, min_samples: 9\n",
      "Scores: [0.43514895 0.44612837 0.4422642  0.53780937 0.51219463], eps: 0.07362068965517242, min_samples: 10\n",
      "Scores: [0.43349069 0.35589474 0.45411247 0.52777493 0.46848881], eps: 0.07362068965517242, min_samples: 11\n",
      "Scores: [0.02781045 0.94879961 0.38615435 0.08341116 0.29837042], eps: 0.10793103448275862, min_samples: 2\n",
      "Scores: [0.08853716 0.40837324 0.37128013 0.34847784 0.4311415 ], eps: 0.10793103448275862, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.10793103448275862, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.10793103448275862, min_samples: 5\n",
      "Scores: [0.30347383 0.45204067 0.40018427 0.43183273 0.45340735], eps: 0.10793103448275862, min_samples: 6\n",
      "Scores: [0.3919552  0.48250699 0.42069793 0.42093128 0.45266289], eps: 0.10793103448275862, min_samples: 7\n",
      "Scores: [0.3919552  0.48250699 0.42069793 0.42093128 0.45266289], eps: 0.10793103448275862, min_samples: 8\n",
      "Scores: [0.35361052 0.43611354 0.38662261 0.37908083 0.47296113], eps: 0.10793103448275862, min_samples: 9\n",
      "Scores: [0.35793012 0.39053249 0.43002337 0.3575654  0.46542305], eps: 0.10793103448275862, min_samples: 10\n",
      "Scores: [0.44237435 0.46064633 0.44077218 0.53831601 0.54226321], eps: 0.10793103448275862, min_samples: 11\n",
      "Scores: [0.06894839 0.91295028 0.44182914 0.07771337 0.13948059], eps: 0.14224137931034483, min_samples: 2\n",
      "Scores: [0.15332836 0.39564407 0.37119228 0.35393834 0.28402835], eps: 0.14224137931034483, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 8\n",
      "Scores: [0.34177464 0.40860277 0.40229267 0.33678031 0.44003952], eps: 0.14224137931034483, min_samples: 9\n",
      "Scores: [0.35039389 0.45046902 0.39460874 0.31238747 0.45046037], eps: 0.14224137931034483, min_samples: 10\n",
      "Scores: [0.34735626 0.43773049 0.45407706 0.3912918  0.4425481 ], eps: 0.14224137931034483, min_samples: 11\n",
      "Scores: [0.07755589 0.91256559 0.44249302 0.09918326 0.00260305], eps: 0.17655172413793105, min_samples: 2\n",
      "Scores: [0.02122712 0.42807317 0.36961305 0.22747535 0.29196578], eps: 0.17655172413793105, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 8\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 9\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 10\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 11\n",
      "Scores: [0.07554173 0.91388345 0.38856232 0.08621901 0.06381524], eps: 0.21086206896551724, min_samples: 2\n",
      "Scores: [0.02562582 0.42532361 0.42342705 0.21896952 0.39008629], eps: 0.21086206896551724, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 8\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 9\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 10\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 11\n",
      "Scores: [0.13097769 0.93461144 0.351542   0.0093323  0.60465443], eps: 0.24517241379310345, min_samples: 2\n",
      "Scores: [0.02562582 0.42532361 0.42342705 0.21896952 0.39008629], eps: 0.24517241379310345, min_samples: 3\n",
      "Scores: [0.14214975 0.44486803 0.42090636 0.32609075 0.33477473], eps: 0.24517241379310345, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 8\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 9\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 10\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 11\n",
      "Scores: [0.19968307 0.90683186 0.31783885 0.2347852  0.48837733], eps: 0.27948275862068966, min_samples: 2\n",
      "Scores: [ 0.1687668  -1.52723598  0.39631164 -0.00256467  0.33445966], eps: 0.27948275862068966, min_samples: 3\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.27948275862068966, min_samples: 4\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.27948275862068966, min_samples: 5\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 6\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 7\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 8\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 9\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 10\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 11\n",
      "Scores: [0.24997151 0.89740694 0.37213516 0.14341581 0.4747178 ], eps: 0.3137931034482759, min_samples: 2\n",
      "Scores: [ 0.18442237 -1.40614581  0.34867436  0.00582182  0.3084169 ], eps: 0.3137931034482759, min_samples: 3\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.3137931034482759, min_samples: 4\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3137931034482759, min_samples: 5\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3137931034482759, min_samples: 6\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 7\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 8\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 9\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 10\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 11\n",
      "Scores: [0.24997151 0.89740694 0.37213516 0.14341581 0.4747178 ], eps: 0.3481034482758621, min_samples: 2\n",
      "Scores: [ 0.18442237 -1.40614581  0.34867436  0.00582182  0.3084169 ], eps: 0.3481034482758621, min_samples: 3\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.3481034482758621, min_samples: 4\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3481034482758621, min_samples: 5\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3481034482758621, min_samples: 6\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 7\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 8\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 9\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 10\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 11\n",
      "Scores: [0.24997151 0.89740694 0.37213516 0.14341581 0.4747178 ], eps: 0.3824137931034483, min_samples: 2\n",
      "Scores: [ 0.18442237 -1.40614581  0.34867436  0.00582182  0.3084169 ], eps: 0.3824137931034483, min_samples: 3\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.3824137931034483, min_samples: 4\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.3824137931034483, min_samples: 5\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3824137931034483, min_samples: 6\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 7\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 8\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 11\n",
      "Scores: [0.24993539 0.87650871 0.33925349 0.20530641 0.49546248], eps: 0.41672413793103447, min_samples: 2\n",
      "Scores: [ 0.14034963 -1.06270361  0.39761633  0.06185222  0.29186743], eps: 0.41672413793103447, min_samples: 3\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.41672413793103447, min_samples: 4\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.41672413793103447, min_samples: 5\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.41672413793103447, min_samples: 6\n",
      "Scores: [0.32166129 0.45293152 0.38965541 0.36160845 0.45109481], eps: 0.41672413793103447, min_samples: 7\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 8\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 11\n",
      "Scores: [0.24554157 0.74749804 0.31838709 0.21810669 0.57302105], eps: 0.4510344827586207, min_samples: 2\n",
      "Scores: [ 0.17127138 -0.24241817  0.37659919  0.15107167  0.2432704 ], eps: 0.4510344827586207, min_samples: 3\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.4510344827586207, min_samples: 4\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.4510344827586207, min_samples: 5\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.4510344827586207, min_samples: 6\n",
      "Scores: [0.18997949 0.38734233 0.42149228 0.35341275 0.47607756], eps: 0.4510344827586207, min_samples: 7\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 8\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.4853448275862069, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.4853448275862069, min_samples: 3\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.4853448275862069, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.4853448275862069, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.4853448275862069, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.4853448275862069, min_samples: 7\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.4853448275862069, min_samples: 8\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.4853448275862069, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4853448275862069, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4853448275862069, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.5196551724137931, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5196551724137931, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5196551724137931, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.5196551724137931, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5196551724137931, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5196551724137931, min_samples: 7\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5196551724137931, min_samples: 8\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5196551724137931, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5196551724137931, min_samples: 10\n",
      "Scores: [0.32166129 0.45293152 0.38965541 0.36160845 0.45109481], eps: 0.5196551724137931, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.5539655172413793, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5539655172413793, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5539655172413793, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.5539655172413793, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5539655172413793, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5539655172413793, min_samples: 7\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.5539655172413793, min_samples: 8\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5539655172413793, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5539655172413793, min_samples: 10\n",
      "Scores: [0.18997949 0.38734233 0.42149228 0.35341275 0.47607756], eps: 0.5539655172413793, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.5882758620689655, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5882758620689655, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5882758620689655, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.5882758620689655, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5882758620689655, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5882758620689655, min_samples: 7\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.5882758620689655, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.5882758620689655, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5882758620689655, min_samples: 10\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5882758620689655, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.6225862068965518, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6225862068965518, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6225862068965518, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.6225862068965518, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6225862068965518, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6225862068965518, min_samples: 7\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6225862068965518, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.6225862068965518, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.6225862068965518, min_samples: 10\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.6225862068965518, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.656896551724138, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.656896551724138, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.656896551724138, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.656896551724138, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.656896551724138, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.656896551724138, min_samples: 7\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.656896551724138, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.656896551724138, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.656896551724138, min_samples: 10\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.656896551724138, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.6912068965517242, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6912068965517242, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6912068965517242, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.6912068965517242, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6912068965517242, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6912068965517242, min_samples: 7\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6912068965517242, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.6912068965517242, min_samples: 9\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.6912068965517242, min_samples: 10\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.6912068965517242, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.7255172413793104, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7255172413793104, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7255172413793104, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.7255172413793104, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7255172413793104, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7255172413793104, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7255172413793104, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7255172413793104, min_samples: 9\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.7255172413793104, min_samples: 10\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.7255172413793104, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.7598275862068966, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7598275862068966, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7598275862068966, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.7598275862068966, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7598275862068966, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7598275862068966, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7598275862068966, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7598275862068966, min_samples: 9\n",
      "Scores: [0.15818292 0.44311327 0.45422691 0.32046288 0.37304378], eps: 0.7598275862068966, min_samples: 10\n",
      "Scores: [0.15818292 0.44311327 0.45422691 0.32046288 0.37304378], eps: 0.7598275862068966, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.7941379310344828, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7941379310344828, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7941379310344828, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.7941379310344828, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 9\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7941379310344828, min_samples: 10\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7941379310344828, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.8284482758620689, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8284482758620689, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8284482758620689, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.8284482758620689, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 9\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8284482758620689, min_samples: 10\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.8284482758620689, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.8627586206896551, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8627586206896551, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8627586206896551, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.8627586206896551, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 9\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8627586206896551, min_samples: 10\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8627586206896551, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.8970689655172414, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8970689655172414, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8970689655172414, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.8970689655172414, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 0.8970689655172414, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 10\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8970689655172414, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.9313793103448276, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9313793103448276, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9313793103448276, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.9313793103448276, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 0.9313793103448276, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 10\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.9656896551724138, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9656896551724138, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9656896551724138, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.9656896551724138, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 0.9656896551724138, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 10\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 1.0, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 1.0, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 1.0, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 1.0, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 1.0, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 10\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 11\n"
     ]
    }
   ],
   "source": [
    "best_score, best_params = fine_tune_DBSCAN(pd.read_csv('xtrainCyclodextrin.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0497eec1-0b5f-447b-bbe3-f10a802f814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5568859457969666, [0.005, 9])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8cd1dce1-eafe-4eb4-ad93-7d64d47546cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.14997065 0.96909994 0.41319847 0.06014425 0.39447373], eps: 0.005, min_samples: 2\n",
      "Scores: [0.4434045  0.4002561  0.46218526 0.45189971 0.46077603], eps: 0.005, min_samples: 3\n",
      "Scores: [0.40436822 0.41689187 0.46293515 0.5911696  0.4882918 ], eps: 0.005, min_samples: 4\n",
      "Scores: [0.58261323 0.48274761 0.58553183 0.59383214 0.48867476], eps: 0.005, min_samples: 5\n",
      "Scores: [0.56922877 0.48300272 0.55187285 0.57108557 0.5050016 ], eps: 0.005, min_samples: 6\n",
      "Scores: [0.55427468 0.45818979 0.64619124 0.54175258 0.46015364], eps: 0.005, min_samples: 7\n",
      "Scores: [0.52532887 0.45715863 0.65867949 0.57440364 0.47494191], eps: 0.005, min_samples: 8\n",
      "Scores: [0.54632008 0.52444392 0.62608314 0.53201556 0.55556703], eps: 0.005, min_samples: 9\n",
      "Scores: [0.53611881 0.4925195  0.59646559 0.47985798 0.5513044 ], eps: 0.005, min_samples: 10\n",
      "Scores: [0.51116431 0.49291873 0.59088403 0.46017957 0.5548296 ], eps: 0.005, min_samples: 11\n",
      "Scores: [-0.01248646  0.94375193  0.41860342  0.07198632  0.36573321], eps: 0.039310344827586205, min_samples: 2\n",
      "Scores: [0.29554969 0.24151289 0.32906532 0.31665212 0.3707903 ], eps: 0.039310344827586205, min_samples: 3\n",
      "Scores: [0.37945485 0.41360962 0.35539514 0.37348133 0.47410333], eps: 0.039310344827586205, min_samples: 4\n",
      "Scores: [0.38091564 0.4386459  0.38335299 0.41838467 0.46976835], eps: 0.039310344827586205, min_samples: 5\n",
      "Scores: [0.3454923  0.37582999 0.38410616 0.48925722 0.46824044], eps: 0.039310344827586205, min_samples: 6\n",
      "Scores: [0.46656591 0.37162238 0.44037813 0.55609262 0.48173541], eps: 0.039310344827586205, min_samples: 7\n",
      "Scores: [0.46493822 0.47126794 0.43925822 0.53744173 0.42047483], eps: 0.039310344827586205, min_samples: 8\n",
      "Scores: [0.45517105 0.37988609 0.54081511 0.58354652 0.48536396], eps: 0.039310344827586205, min_samples: 9\n",
      "Scores: [0.45517105 0.37988609 0.54081511 0.58354652 0.48536396], eps: 0.039310344827586205, min_samples: 10\n",
      "Scores: [0.44471323 0.43789077 0.53046656 0.59874547 0.49577475], eps: 0.039310344827586205, min_samples: 11\n",
      "Scores: [-0.00783861  0.93876034  0.41166741  0.06456983  0.40568292], eps: 0.07362068965517242, min_samples: 2\n",
      "Scores: [0.07749844 0.37858438 0.38343596 0.39992374 0.48907894], eps: 0.07362068965517242, min_samples: 3\n",
      "Scores: [0.32741058 0.41366792 0.433249   0.43381172 0.4240554 ], eps: 0.07362068965517242, min_samples: 4\n",
      "Scores: [0.36632586 0.31635177 0.45287818 0.34516674 0.43877333], eps: 0.07362068965517242, min_samples: 5\n",
      "Scores: [0.36632586 0.31635177 0.45287818 0.34516674 0.43877333], eps: 0.07362068965517242, min_samples: 6\n",
      "Scores: [0.36632586 0.31635177 0.45287818 0.34516674 0.43877333], eps: 0.07362068965517242, min_samples: 7\n",
      "Scores: [0.3860206  0.28896511 0.44651109 0.38233399 0.47489858], eps: 0.07362068965517242, min_samples: 8\n",
      "Scores: [0.42633659 0.45607293 0.43886638 0.54834509 0.5410763 ], eps: 0.07362068965517242, min_samples: 9\n",
      "Scores: [0.43514895 0.44612837 0.4422642  0.53780937 0.51219463], eps: 0.07362068965517242, min_samples: 10\n",
      "Scores: [0.43349069 0.35589474 0.45411247 0.52777493 0.46848881], eps: 0.07362068965517242, min_samples: 11\n",
      "Scores: [0.02781045 0.94879961 0.38615435 0.08341116 0.29837042], eps: 0.10793103448275862, min_samples: 2\n",
      "Scores: [0.08853716 0.40837324 0.37128013 0.34847784 0.4311415 ], eps: 0.10793103448275862, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.10793103448275862, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.10793103448275862, min_samples: 5\n",
      "Scores: [0.30347383 0.45204067 0.40018427 0.43183273 0.45340735], eps: 0.10793103448275862, min_samples: 6\n",
      "Scores: [0.3919552  0.48250699 0.42069793 0.42093128 0.45266289], eps: 0.10793103448275862, min_samples: 7\n",
      "Scores: [0.3919552  0.48250699 0.42069793 0.42093128 0.45266289], eps: 0.10793103448275862, min_samples: 8\n",
      "Scores: [0.35361052 0.43611354 0.38662261 0.37908083 0.47296113], eps: 0.10793103448275862, min_samples: 9\n",
      "Scores: [0.35793012 0.39053249 0.43002337 0.3575654  0.46542305], eps: 0.10793103448275862, min_samples: 10\n",
      "Scores: [0.44237435 0.46064633 0.44077218 0.53831601 0.54226321], eps: 0.10793103448275862, min_samples: 11\n",
      "Scores: [0.06894839 0.91295028 0.44182914 0.07771337 0.13948059], eps: 0.14224137931034483, min_samples: 2\n",
      "Scores: [0.15332836 0.39564407 0.37119228 0.35393834 0.28402835], eps: 0.14224137931034483, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.14224137931034483, min_samples: 8\n",
      "Scores: [0.34177464 0.40860277 0.40229267 0.33678031 0.44003952], eps: 0.14224137931034483, min_samples: 9\n",
      "Scores: [0.35039389 0.45046902 0.39460874 0.31238747 0.45046037], eps: 0.14224137931034483, min_samples: 10\n",
      "Scores: [0.34735626 0.43773049 0.45407706 0.3912918  0.4425481 ], eps: 0.14224137931034483, min_samples: 11\n",
      "Scores: [0.07755589 0.91256559 0.44249302 0.09918326 0.00260305], eps: 0.17655172413793105, min_samples: 2\n",
      "Scores: [0.02122712 0.42807317 0.36961305 0.22747535 0.29196578], eps: 0.17655172413793105, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 8\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 9\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 10\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.17655172413793105, min_samples: 11\n",
      "Scores: [0.07554173 0.91388345 0.38856232 0.08621901 0.06381524], eps: 0.21086206896551724, min_samples: 2\n",
      "Scores: [0.02562582 0.42532361 0.42342705 0.21896952 0.39008629], eps: 0.21086206896551724, min_samples: 3\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 8\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 9\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 10\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.21086206896551724, min_samples: 11\n",
      "Scores: [0.13097769 0.93461144 0.351542   0.0093323  0.60465443], eps: 0.24517241379310345, min_samples: 2\n",
      "Scores: [0.02562582 0.42532361 0.42342705 0.21896952 0.39008629], eps: 0.24517241379310345, min_samples: 3\n",
      "Scores: [0.14214975 0.44486803 0.42090636 0.32609075 0.33477473], eps: 0.24517241379310345, min_samples: 4\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 5\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 6\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 7\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 8\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 9\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 10\n",
      "Scores: [0.32727933 0.50806785 0.335899   0.41609532 0.42953283], eps: 0.24517241379310345, min_samples: 11\n",
      "Scores: [0.19968307 0.90683186 0.31783885 0.2347852  0.48837733], eps: 0.27948275862068966, min_samples: 2\n",
      "Scores: [ 0.1687668  -1.52723598  0.39631164 -0.00256467  0.33445966], eps: 0.27948275862068966, min_samples: 3\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.27948275862068966, min_samples: 4\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.27948275862068966, min_samples: 5\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 6\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 7\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 8\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 9\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 10\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.27948275862068966, min_samples: 11\n",
      "Scores: [0.24997151 0.89740694 0.37213516 0.14341581 0.4747178 ], eps: 0.3137931034482759, min_samples: 2\n",
      "Scores: [ 0.18442237 -1.40614581  0.34867436  0.00582182  0.3084169 ], eps: 0.3137931034482759, min_samples: 3\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.3137931034482759, min_samples: 4\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3137931034482759, min_samples: 5\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3137931034482759, min_samples: 6\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 7\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 8\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 9\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 10\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3137931034482759, min_samples: 11\n",
      "Scores: [0.24997151 0.89740694 0.37213516 0.14341581 0.4747178 ], eps: 0.3481034482758621, min_samples: 2\n",
      "Scores: [ 0.18442237 -1.40614581  0.34867436  0.00582182  0.3084169 ], eps: 0.3481034482758621, min_samples: 3\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.3481034482758621, min_samples: 4\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3481034482758621, min_samples: 5\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3481034482758621, min_samples: 6\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 7\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 8\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 9\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 10\n",
      "Scores: [0.30748624 0.4176507  0.37865669 0.43383497 0.48132074], eps: 0.3481034482758621, min_samples: 11\n",
      "Scores: [0.24997151 0.89740694 0.37213516 0.14341581 0.4747178 ], eps: 0.3824137931034483, min_samples: 2\n",
      "Scores: [ 0.18442237 -1.40614581  0.34867436  0.00582182  0.3084169 ], eps: 0.3824137931034483, min_samples: 3\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.3824137931034483, min_samples: 4\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.3824137931034483, min_samples: 5\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.3824137931034483, min_samples: 6\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 7\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 8\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.3824137931034483, min_samples: 11\n",
      "Scores: [0.24993539 0.87650871 0.33925349 0.20530641 0.49546248], eps: 0.41672413793103447, min_samples: 2\n",
      "Scores: [ 0.14034963 -1.06270361  0.39761633  0.06185222  0.29186743], eps: 0.41672413793103447, min_samples: 3\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.41672413793103447, min_samples: 4\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.41672413793103447, min_samples: 5\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.41672413793103447, min_samples: 6\n",
      "Scores: [0.32166129 0.45293152 0.38965541 0.36160845 0.45109481], eps: 0.41672413793103447, min_samples: 7\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 8\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.41672413793103447, min_samples: 11\n",
      "Scores: [0.24554157 0.74749804 0.31838709 0.21810669 0.57302105], eps: 0.4510344827586207, min_samples: 2\n",
      "Scores: [ 0.17127138 -0.24241817  0.37659919  0.15107167  0.2432704 ], eps: 0.4510344827586207, min_samples: 3\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.4510344827586207, min_samples: 4\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.4510344827586207, min_samples: 5\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.4510344827586207, min_samples: 6\n",
      "Scores: [0.18997949 0.38734233 0.42149228 0.35341275 0.47607756], eps: 0.4510344827586207, min_samples: 7\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 8\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4510344827586207, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.4853448275862069, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.4853448275862069, min_samples: 3\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.4853448275862069, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.4853448275862069, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.4853448275862069, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.4853448275862069, min_samples: 7\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.4853448275862069, min_samples: 8\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.4853448275862069, min_samples: 9\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4853448275862069, min_samples: 10\n",
      "Scores: [0.30910093 0.41035879 0.40133566 0.41728324 0.4670853 ], eps: 0.4853448275862069, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.5196551724137931, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5196551724137931, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5196551724137931, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.5196551724137931, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5196551724137931, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5196551724137931, min_samples: 7\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5196551724137931, min_samples: 8\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5196551724137931, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5196551724137931, min_samples: 10\n",
      "Scores: [0.32166129 0.45293152 0.38965541 0.36160845 0.45109481], eps: 0.5196551724137931, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.5539655172413793, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5539655172413793, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5539655172413793, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.5539655172413793, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5539655172413793, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5539655172413793, min_samples: 7\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.5539655172413793, min_samples: 8\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5539655172413793, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5539655172413793, min_samples: 10\n",
      "Scores: [0.18997949 0.38734233 0.42149228 0.35341275 0.47607756], eps: 0.5539655172413793, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.5882758620689655, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5882758620689655, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.5882758620689655, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.5882758620689655, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5882758620689655, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.5882758620689655, min_samples: 7\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.5882758620689655, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.5882758620689655, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5882758620689655, min_samples: 10\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.5882758620689655, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.6225862068965518, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6225862068965518, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6225862068965518, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.6225862068965518, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6225862068965518, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6225862068965518, min_samples: 7\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6225862068965518, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.6225862068965518, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.6225862068965518, min_samples: 10\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.6225862068965518, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.656896551724138, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.656896551724138, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.656896551724138, min_samples: 4\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.656896551724138, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.656896551724138, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.656896551724138, min_samples: 7\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.656896551724138, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.656896551724138, min_samples: 9\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.656896551724138, min_samples: 10\n",
      "Scores: [0.14128876 0.39953429 0.42120963 0.3265295  0.46223205], eps: 0.656896551724138, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.6912068965517242, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6912068965517242, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.6912068965517242, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.6912068965517242, min_samples: 5\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6912068965517242, min_samples: 6\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6912068965517242, min_samples: 7\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.6912068965517242, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.6912068965517242, min_samples: 9\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.6912068965517242, min_samples: 10\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.6912068965517242, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.7255172413793104, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7255172413793104, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7255172413793104, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.7255172413793104, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7255172413793104, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7255172413793104, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7255172413793104, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7255172413793104, min_samples: 9\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.7255172413793104, min_samples: 10\n",
      "Scores: [0.13219786 0.4142977  0.44647723 0.30701697 0.4634245 ], eps: 0.7255172413793104, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.7598275862068966, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7598275862068966, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7598275862068966, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.7598275862068966, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7598275862068966, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7598275862068966, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7598275862068966, min_samples: 8\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7598275862068966, min_samples: 9\n",
      "Scores: [0.15818292 0.44311327 0.45422691 0.32046288 0.37304378], eps: 0.7598275862068966, min_samples: 10\n",
      "Scores: [0.15818292 0.44311327 0.45422691 0.32046288 0.37304378], eps: 0.7598275862068966, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.7941379310344828, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7941379310344828, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.7941379310344828, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.7941379310344828, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.7941379310344828, min_samples: 9\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7941379310344828, min_samples: 10\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.7941379310344828, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.8284482758620689, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8284482758620689, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8284482758620689, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.8284482758620689, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8284482758620689, min_samples: 9\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8284482758620689, min_samples: 10\n",
      "Scores: [0.22131747 0.45931172 0.41984034 0.35600609 0.4021666 ], eps: 0.8284482758620689, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.8627586206896551, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8627586206896551, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8627586206896551, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.8627586206896551, min_samples: 5\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8627586206896551, min_samples: 9\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8627586206896551, min_samples: 10\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8627586206896551, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.8970689655172414, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8970689655172414, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.8970689655172414, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.8970689655172414, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 0.8970689655172414, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.8970689655172414, min_samples: 10\n",
      "Scores: [0.17912292 0.437343   0.36971039 0.3682667  0.36228949], eps: 0.8970689655172414, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.9313793103448276, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9313793103448276, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9313793103448276, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.9313793103448276, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 0.9313793103448276, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 10\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9313793103448276, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 0.9656896551724138, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9656896551724138, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 0.9656896551724138, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 0.9656896551724138, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 0.9656896551724138, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 10\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 0.9656896551724138, min_samples: 11\n",
      "Scores: [0.24285448 0.73761153 0.32609421 0.25214362 0.60503888], eps: 1.0, min_samples: 2\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 1.0, min_samples: 3\n",
      "Scores: [ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643], eps: 1.0, min_samples: 4\n",
      "Scores: [0.06392145 0.47659427 0.332699   0.22265494 0.43285495], eps: 1.0, min_samples: 5\n",
      "Scores: [0.16794425 0.39273268 0.35020721 0.37325597 0.43879586], eps: 1.0, min_samples: 6\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 7\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 8\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 9\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 10\n",
      "Scores: [0.18962598 0.41859746 0.36000526 0.34957695 0.36912626], eps: 1.0, min_samples: 11\n",
      "Best Score: 0.11345893144607544, Params: [0.01, 0.0, 50, 2, 0.6, 0.6, 0, 1]\n",
      "Best Score: 0.13254676262537637, Params: [0.01, 0.0, 50, 2, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.14039669434229532, Params: [0.01, 0.0, 50, 2, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.14985235532124838, Params: [0.01, 0.0, 50, 3, 0.6, 0.6, 0, 1]\n",
      "Best Score: 0.1697710951169332, Params: [0.01, 0.0, 50, 3, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.17879629135131836, Params: [0.01, 0.0, 50, 3, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.17886332670847574, Params: [0.01, 0.0, 50, 3, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.18178959687550864, Params: [0.01, 0.0, 50, 4, 0.6, 0.6, 0, 1]\n",
      "Best Score: 0.2041297753651937, Params: [0.01, 0.0, 50, 4, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.21312278509140015, Params: [0.01, 0.0, 50, 4, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.2286598483721415, Params: [0.01, 0.0, 50, 5, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.2392991582552592, Params: [0.01, 0.0, 50, 5, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.24335843324661255, Params: [0.01, 0.0, 50, 5, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.2493158976236979, Params: [0.01, 0.0, 50, 6, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.24932928880055746, Params: [0.01, 0.0, 50, 6, 0.6, 0.8, 1, 1]\n",
      "Best Score: 0.2601674795150757, Params: [0.01, 0.0, 50, 6, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.2602081894874573, Params: [0.01, 0.0, 50, 6, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.26683364311854046, Params: [0.01, 0.0, 50, 6, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.2668638030687968, Params: [0.01, 0.0, 50, 6, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.2733275890350342, Params: [0.01, 0.0, 50, 7, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.2830380400021871, Params: [0.01, 0.0, 50, 7, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.2856088876724243, Params: [0.01, 0.0, 50, 7, 1.0, 1.0, 0, 1]\n",
      "Best Score: 0.2950803240140279, Params: [0.01, 0.0, 50, 8, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.29509397347768146, Params: [0.01, 0.0, 50, 8, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.29838605721791583, Params: [0.01, 0.0, 50, 8, 1.0, 1.0, 0, 1]\n",
      "Best Score: 0.3047010699907939, Params: [0.01, 0.0, 50, 9, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.3059404492378235, Params: [0.01, 0.0, 50, 9, 1.0, 1.0, 0, 1]\n",
      "Best Score: 0.3060879707336426, Params: [0.01, 0.0, 50, 9, 1.0, 1.0, 1, 1]\n",
      "Best Score: 0.3087695638338725, Params: [0.01, 0.0, 50, 10, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.3087759017944336, Params: [0.01, 0.0, 50, 10, 0.8, 1.0, 0.1, 1]\n",
      "Best Score: 0.3120654026667277, Params: [0.01, 0.0, 50, 11, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.31260959307352704, Params: [0.01, 0.0, 100, 4, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.31949687004089355, Params: [0.01, 0.0, 100, 4, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.3195001681645711, Params: [0.01, 0.0, 100, 4, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.31993502378463745, Params: [0.01, 0.0, 100, 4, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.330280343691508, Params: [0.01, 0.0, 100, 5, 0.6, 0.6, 0, 1]\n",
      "Best Score: 0.347065269947052, Params: [0.01, 0.0, 100, 5, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.35463736454645794, Params: [0.01, 0.0, 100, 5, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.3547449509302775, Params: [0.01, 0.0, 100, 5, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.35487955808639526, Params: [0.01, 0.0, 100, 5, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.3593163688977559, Params: [0.01, 0.0, 100, 5, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.35932918389638263, Params: [0.01, 0.0, 100, 5, 0.8, 1.0, 0.1, 1]\n",
      "Best Score: 0.35943082968393963, Params: [0.01, 0.0, 100, 5, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.37397197882334393, Params: [0.01, 0.0, 100, 6, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.3740276098251343, Params: [0.01, 0.0, 100, 6, 0.6, 0.8, 1, 1]\n",
      "Best Score: 0.3825829029083252, Params: [0.01, 0.0, 100, 6, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.3830242355664571, Params: [0.01, 0.0, 100, 6, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.38335973024368286, Params: [0.01, 0.0, 100, 6, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.39043164253234863, Params: [0.01, 0.0, 100, 6, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.3904623786608378, Params: [0.01, 0.0, 100, 6, 0.8, 1.0, 0.1, 1]\n",
      "Best Score: 0.39355550209681195, Params: [0.01, 0.0, 100, 7, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.3937237064043681, Params: [0.01, 0.0, 100, 7, 0.6, 0.8, 1, 1]\n",
      "Best Score: 0.4018467664718628, Params: [0.01, 0.0, 100, 7, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.40187132358551025, Params: [0.01, 0.0, 100, 7, 0.6, 1.0, 0.1, 1]\n",
      "Best Score: 0.402782678604126, Params: [0.01, 0.0, 100, 7, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.41058699289957684, Params: [0.01, 0.0, 100, 7, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.41064751148223877, Params: [0.01, 0.0, 100, 7, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.41281090180079144, Params: [0.01, 0.0, 100, 8, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.418403426806132, Params: [0.01, 0.0, 100, 8, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.4185340205828349, Params: [0.01, 0.0, 100, 8, 0.8, 0.8, 0.1, 1]\n",
      "Best Score: 0.42662038405736286, Params: [0.01, 0.0, 100, 8, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.4266514182090759, Params: [0.01, 0.0, 100, 8, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.42827550570170086, Params: [0.01, 0.0, 100, 9, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.42850732803344727, Params: [0.01, 0.0, 100, 9, 0.8, 0.8, 1, 1]\n",
      "Best Score: 0.4370008111000061, Params: [0.01, 0.0, 100, 9, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.43711715936660767, Params: [0.01, 0.0, 100, 9, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.4414532979329427, Params: [0.01, 0.0, 100, 10, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.4416507879892985, Params: [0.01, 0.0, 100, 10, 0.8, 1.0, 0.1, 1]\n",
      "Best Score: 0.44165511926015216, Params: [0.01, 0.0, 100, 10, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.44615397850672406, Params: [0.01, 0.0, 100, 11, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.44637755552927655, Params: [0.01, 0.0, 100, 11, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.4565114974975586, Params: [0.01, 0.0, 200, 5, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.45678865909576416, Params: [0.01, 0.0, 200, 5, 0.6, 0.8, 1, 1]\n",
      "Best Score: 0.45703423023223877, Params: [0.01, 0.0, 200, 5, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.457634965578715, Params: [0.01, 0.0, 200, 5, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.46276650826136273, Params: [0.01, 0.0, 200, 5, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.46277562777201336, Params: [0.01, 0.0, 200, 5, 0.8, 0.8, 1, 1]\n",
      "Best Score: 0.46392889817555744, Params: [0.01, 0.0, 200, 5, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.46397759517033893, Params: [0.01, 0.0, 200, 5, 0.8, 1.0, 0.1, 1]\n",
      "Best Score: 0.4667159716288249, Params: [0.01, 0.0, 200, 6, 0.6, 0.6, 0, 1]\n",
      "Best Score: 0.466810663541158, Params: [0.01, 0.0, 200, 6, 0.6, 0.6, 0.1, 1]\n",
      "Best Score: 0.48367055257161456, Params: [0.01, 0.0, 200, 6, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.4837062954902649, Params: [0.01, 0.0, 200, 6, 0.6, 0.8, 0.1, 1]\n",
      "Best Score: 0.4855581720670064, Params: [0.01, 0.0, 200, 6, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.4860859115918477, Params: [0.01, 0.0, 200, 6, 0.6, 1.0, 1, 1]\n",
      "Best Score: 0.49008482694625854, Params: [0.01, 0.0, 200, 6, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.49098410209019977, Params: [0.01, 0.0, 200, 6, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.5017735560735067, Params: [0.01, 0.0, 200, 7, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.5018293062845866, Params: [0.01, 0.0, 200, 7, 0.6, 0.8, 0.1, 1]\n",
      "Best Score: 0.5021599332491556, Params: [0.01, 0.0, 200, 7, 0.6, 1.0, 0, 1]\n",
      "Best Score: 0.5079571207364401, Params: [0.01, 0.0, 200, 7, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.5087840755780538, Params: [0.01, 0.0, 200, 7, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.5089537700017294, Params: [0.01, 0.0, 200, 7, 0.8, 1.0, 0.1, 1]\n",
      "Best Score: 0.5092059771219889, Params: [0.01, 0.0, 200, 7, 0.8, 1.0, 1, 1]\n",
      "Best Score: 0.5121133128801981, Params: [0.01, 0.0, 200, 8, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.5124017397562662, Params: [0.01, 0.0, 200, 8, 0.6, 0.8, 0.1, 1]\n",
      "Best Score: 0.5125669042269388, Params: [0.01, 0.0, 200, 8, 0.6, 1.0, 0.1, 1]\n",
      "Best Score: 0.5195256074269613, Params: [0.01, 0.0, 200, 8, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.519853432973226, Params: [0.01, 0.0, 200, 8, 0.8, 0.8, 0.1, 1]\n",
      "Best Score: 0.5211485822995504, Params: [0.01, 0.0, 200, 8, 0.8, 1.0, 0, 1]\n",
      "Best Score: 0.5274869203567505, Params: [0.01, 0.0, 200, 9, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.5276545882225037, Params: [0.01, 0.0, 200, 9, 0.8, 0.8, 1, 1]\n",
      "Best Score: 0.5309042731920878, Params: [0.01, 0.0, 200, 10, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.5310955246289571, Params: [0.01, 0.0, 200, 11, 0.8, 0.8, 1, 1]\n",
      "Best Score: 0.5378113190333048, Params: [0.01, 0.0, 400, 6, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.5398408770561218, Params: [0.01, 0.0, 400, 6, 0.8, 0.6, 0, 1]\n",
      "Best Score: 0.5417416493097941, Params: [0.01, 0.0, 400, 6, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.5421417355537415, Params: [0.01, 0.0, 400, 6, 0.8, 0.8, 0.1, 1]\n",
      "Best Score: 0.5421879887580872, Params: [0.01, 0.0, 400, 7, 0.6, 0.6, 0, 1.5]\n",
      "Best Score: 0.5424124399820963, Params: [0.01, 0.0, 400, 7, 0.6, 0.6, 0.1, 1]\n",
      "Best Score: 0.5426490505536398, Params: [0.01, 0.0, 400, 7, 0.6, 0.6, 1, 1]\n",
      "Best Score: 0.5427831013997396, Params: [0.01, 0.0, 400, 7, 0.6, 0.6, 1, 1.5]\n",
      "Best Score: 0.5486883918444315, Params: [0.01, 0.0, 400, 7, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.5513079563776652, Params: [0.01, 0.0, 400, 7, 0.8, 0.6, 0, 1]\n",
      "Best Score: 0.5515397787094116, Params: [0.01, 0.0, 400, 7, 0.8, 0.6, 0.1, 1]\n",
      "Best Score: 0.5533277789751688, Params: [0.01, 0.0, 400, 7, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.5567853252092997, Params: [0.01, 0.0, 400, 8, 0.6, 0.8, 0, 1]\n",
      "Best Score: 0.5575078725814819, Params: [0.01, 0.0, 400, 8, 0.6, 0.8, 0.1, 1]\n",
      "Best Score: 0.5591878890991211, Params: [0.01, 0.0, 400, 8, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.559469739596049, Params: [0.01, 0.0, 400, 8, 0.8, 0.8, 0, 1.5]\n",
      "Best Score: 0.5594708522160848, Params: [0.01, 0.0, 400, 8, 0.8, 0.8, 0.1, 1]\n",
      "Best Score: 0.5600974957148234, Params: [0.01, 0.0, 400, 8, 0.8, 0.8, 0.1, 1.5]\n",
      "Best Score: 0.5611367026964823, Params: [0.01, 0.0, 400, 8, 0.8, 0.8, 1, 1.5]\n",
      "Best Score: 0.5615159869194031, Params: [0.01, 0.0, 400, 9, 0.6, 0.8, 0, 1.5]\n",
      "Best Score: 0.563593864440918, Params: [0.01, 0.0, 400, 9, 0.8, 0.8, 0, 1]\n",
      "Best Score: 0.5637923081715902, Params: [0.01, 0.0, 400, 9, 0.8, 0.8, 0.1, 1]\n",
      "Best Score: 0.5638871987660726, Params: [0.01, 0.0, 400, 9, 0.8, 0.8, 1, 1]\n",
      "Best Score: 0.5639313658078512, Params: [0.01, 0.0, 400, 10, 0.8, 0.8, 0.1, 1]\n",
      "Best Score: 0.5642179052035013, Params: [0.01, 0.0, 600, 8, 0.8, 0.8, 0, 1.5]\n",
      "Best Score: 0.564914325873057, Params: [0.01, 0.0, 600, 8, 0.8, 0.8, 0.1, 1.5]\n",
      "Best Score: 0.5654181639353434, Params: [0.01, 0.0, 600, 8, 0.8, 0.8, 1, 1.5]\n",
      "Best Score: 0.5667996009190878, Params: [0.01, 0.0, 600, 9, 0.6, 0.8, 0, 1.5]\n",
      "Best Score: 0.5671882232030233, Params: [0.01, 0.0, 600, 11, 0.6, 0.8, 0, 1.5]\n",
      "Best Score: 0.567195475101471, Params: [0.01, 0.0, 600, 11, 0.6, 0.8, 0.1, 1.5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_score,best_params,best_score_xg,best_params_xg \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_DBSCAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxtrainCyclodextrin.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[83], line 124\u001b[0m, in \u001b[0;36mfine_tune_DBSCAN\u001b[1;34m(dataset_train)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr, Gamma, n_est, md, sub, col, Rega, Regl \u001b[38;5;129;01min\u001b[39;00m combinations:\n\u001b[0;32m    112\u001b[0m     XG_reg \u001b[38;5;241m=\u001b[39m XGBRegressor(\n\u001b[0;32m    113\u001b[0m         booster\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    114\u001b[0m         gamma\u001b[38;5;241m=\u001b[39mGamma,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m         colsample_bytree\u001b[38;5;241m=\u001b[39mcol\n\u001b[0;32m    123\u001b[0m     )\n\u001b[1;32m--> 124\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXG_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m>\u001b[39m best_score_xg:\n\u001b[0;32m    126\u001b[0m         best_score_xg \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m-> 1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score,best_params,best_score_xg,best_params_xg = fine_tune_DBSCAN(pd.read_csv('xtrainCyclodextrin.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15b67bad-f630-4838-9f88-fbd63ae0bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "import itertools\n",
    "\n",
    "def fine_tune_DBSCAN(dataset_train):\n",
    "    # Define hyperparameter ranges\n",
    "    L_R = np.linspace(0.01, 0.5, 2)  # Test different learning rates\n",
    "    gamma = np.linspace(0, 3, 2)\n",
    "    N_estimators = [50, 100]  # Number of boosting rounds\n",
    "    MDepth = [i for i in range(2, 4)]  # Depth of trees\n",
    "    SUBSAMPLE = [0.6]  # Fraction of samples used per tree\n",
    "    COLSAMPLE_BYTREE = [0.6]  # Fraction of features used per tree\n",
    "    REG_ALPHA = [0, 0.1, 1]  # L1 regularization\n",
    "    REG_LAMBDA = [1]  # L2 regularization\n",
    "    eps_values = np.linspace(0.005, 1.0, 3)  # Range of epsilon values\n",
    "    min_samples_values = [2, 3]  # Different min_samples\n",
    "\n",
    "    best_score = 0\n",
    "    best_params = [0, 0]\n",
    "    best_score_xg = 0\n",
    "\n",
    "    # Generate combinations of XGBoost parameters\n",
    "    combinations = itertools.product(L_R, gamma, N_estimators, MDepth, SUBSAMPLE, COLSAMPLE_BYTREE, REG_ALPHA, REG_LAMBDA)\n",
    "\n",
    "    for eps_val in eps_values:\n",
    "        for sample in min_samples_values:\n",
    "            x_train = dataset_train.copy()\n",
    "            selected_columns = ['K']\n",
    "            X = x_train[selected_columns]\n",
    "            \n",
    "            # Scale the data\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "            \n",
    "            # Apply DBSCAN\n",
    "            dbscan = DBSCAN(eps=eps_val, min_samples=sample)\n",
    "            labels = dbscan.fit_predict(X_scaled)\n",
    "            \n",
    "            # Identify outliers\n",
    "            x_train['Cluster'] = labels\n",
    "            outliers = x_train[x_train['Cluster'] == -1]\n",
    "            x_train = x_train[x_train['Cluster'] != -1].drop(['Cluster'], axis=1)\n",
    "            \n",
    "            # Calculate Error\n",
    "            Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].notnull(), \"logK\"]) - x_train.loc[x_train[\"logK\"].notnull(), \"K\"]) / 10\n",
    "            x_train.loc[x_train[\"Erreur\"].isnull(), \"Erreur\"] = Erreur\n",
    "            y_train = x_train['K']\n",
    "            x_train = x_train.drop(['Original_Value', 'Guest', \"Reference\", \"CID_Guest\", \"IsomericSMILES_Host\",\n",
    "                                    \"IsomericSMILES\", 'Charge_Host', 'K', 'logK'], axis=1)\n",
    "            \n",
    "            # Encode categorical variables\n",
    "            categorical_columns = [\"Host\"]\n",
    "            Onehot = [\"Host\"]\n",
    "            label_encoder = []  # Add label encoding columns if needed\n",
    "            for col in label_encoder:\n",
    "                x_train[col] = LabelEncoder().fit_transform(x_train[col])\n",
    "            remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "            ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), Onehot)], \n",
    "                                   remainder='passthrough')\n",
    "            x_train_array = ct.fit_transform(x_train)\n",
    "            encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "            all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "            x_train = pd.DataFrame(x_train_array, columns=all_feature_names)\n",
    "            \n",
    "            # Evaluate model with cross-validation\n",
    "            XG_reg = XGBRegressor(\n",
    "                booster='gbtree',\n",
    "                learning_rate=0.01,\n",
    "                n_estimators=800,\n",
    "                random_state=42,\n",
    "                max_depth=6\n",
    "            )\n",
    "            scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=5, scoring='r2')\n",
    "            print(scores)\n",
    "            print(\"This is eps:\", eps_val, \"This is sample:\", sample)\n",
    "            if best_score < scores.mean():\n",
    "                best_score = scores.mean()\n",
    "                best_params = [eps_val, sample]\n",
    "\n",
    "    # Final DBSCAN with best parameters\n",
    "    x_train = dataset_train.copy()\n",
    "    X = x_train[selected_columns]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    dbscan = DBSCAN(eps=best_params[0], min_samples=best_params[1])\n",
    "    labels = dbscan.fit_predict(X_scaled)\n",
    "    x_train['Cluster'] = labels\n",
    "    outliers = x_train[x_train['Cluster'] == -1]\n",
    "    x_train = x_train[x_train['Cluster'] != -1].drop(['Cluster'], axis=1)\n",
    "    Erreur = np.abs(np.exp(x_train.loc[x_train[\"logK\"].notnull(), \"logK\"]) - x_train.loc[x_train[\"logK\"].notnull(), \"K\"]) / 10\n",
    "    x_train.loc[x_train[\"Erreur\"].isnull(), \"Erreur\"] = Erreur\n",
    "    y_train = x_train['K']\n",
    "    x_train = x_train.drop(['Original_Value', 'Guest', \"Reference\", \"CID_Guest\", \"IsomericSMILES_Host\",\n",
    "                            \"IsomericSMILES\", 'Charge_Host', 'K', 'logK'], axis=1)\n",
    "    categorical_columns = [\"Host\"]\n",
    "    Onehot = [\"Host\"]\n",
    "    label_encoder = []  # Add label encoding columns if needed\n",
    "    for col in label_encoder:\n",
    "        x_train[col] = LabelEncoder().fit_transform(x_train[col])\n",
    "    remainder_cols = [col for col in x_train.columns if col not in categorical_columns]\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), Onehot)], \n",
    "                           remainder='passthrough')\n",
    "    x_train_array = ct.fit_transform(x_train)\n",
    "    encoded_feature_names = ct.named_transformers_['encoder'].get_feature_names_out(categorical_columns)\n",
    "    all_feature_names = list(encoded_feature_names) + remainder_cols\n",
    "    x_train = pd.DataFrame(x_train_array, columns=all_feature_names)\n",
    "    \n",
    "    # Fine-tune XGBoost with all parameter combinations\n",
    "    for lr, Gamma, n_est, md, sub, col, Rega, Regl in combinations:\n",
    "        XG_reg = XGBRegressor(\n",
    "            booster='gbtree',\n",
    "            gamma=Gamma,\n",
    "            learning_rate=lr,\n",
    "            n_estimators=n_est,\n",
    "            random_state=42,\n",
    "            max_depth=md,\n",
    "            reg_lambda=Regl,\n",
    "            reg_alpha=Rega,\n",
    "            subsample=sub,\n",
    "            colsample_bytree=col\n",
    "        )\n",
    "        scores = cross_val_score(estimator=XG_reg, X=x_train.values, y=y_train, cv=3, scoring='r2')\n",
    "        if scores.mean() > best_score_xg:\n",
    "            best_score_xg = scores.mean()\n",
    "            best_params_xg = [lr, Gamma, n_est, md, sub, col, Rega, Regl]\n",
    "            print(\"This is the best score:\", best_score_xg)\n",
    "            print(\"For the following params:\", best_params_xg)\n",
    "\n",
    "    return best_score, best_params, best_score_xg, best_params_xg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06668416-49f1-4a7b-b421-03f1b0069e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14997065 0.96909994 0.41319847 0.06014425 0.39447373]\n",
      "This is eps: 0.005 This is sample: 2\n",
      "[0.4434045  0.4002561  0.46218526 0.45189971 0.46077603]\n",
      "This is eps: 0.005 This is sample: 3\n",
      "[0.24285448 0.73761153 0.32609421 0.25214362 0.60503888]\n",
      "This is eps: 0.5025 This is sample: 2\n",
      "[ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643]\n",
      "This is eps: 0.5025 This is sample: 3\n",
      "[0.24285448 0.73761153 0.32609421 0.25214362 0.60503888]\n",
      "This is eps: 1.0 This is sample: 2\n",
      "[ 0.20488507 -0.15495217  0.37327415  0.18388313  0.22379643]\n",
      "This is eps: 1.0 This is sample: 3\n",
      "This is the best score: 0.10860623915990193\n",
      "For the following params: [0.01, 0.0, 50, 2, 0.6, 0.6, 0, 1]\n",
      "This is the best score: 0.14107739925384521\n",
      "For the following params: [0.01, 0.0, 50, 3, 0.6, 0.6, 0, 1]\n",
      "This is the best score: 0.18798838059107462\n",
      "For the following params: [0.01, 0.0, 100, 2, 0.6, 0.6, 0, 1]\n",
      "This is the best score: 0.23904808362325033\n",
      "For the following params: [0.01, 0.0, 100, 3, 0.6, 0.6, 0, 1]\n",
      "This is the best score: 0.3503897388776143\n",
      "For the following params: [0.5, 0.0, 50, 2, 0.6, 0.6, 0, 1]\n",
      "This is the best score: 0.3503904740015666\n",
      "For the following params: [0.5, 0.0, 50, 2, 0.6, 0.6, 0.1, 1]\n",
      "This is the best score: 0.3503970503807068\n",
      "For the following params: [0.5, 0.0, 50, 2, 0.6, 0.6, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "best_score,best_params,best_score_xg,best_params_xg = fine_tune_DBSCAN(pd.read_csv('xtrainCyclodextrin.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c92d3-9956-46cd-90a9-656117029dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
